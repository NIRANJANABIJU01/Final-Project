{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNbRav3CRFMgEMHUiuWtjV5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOjKh10ybTMf","executionInfo":{"status":"ok","timestamp":1724184978136,"user_tz":-60,"elapsed":21593,"user":{"displayName":"Niranjana B","userId":"06291036233969807225"}},"outputId":"5039f006-e58d-4e67-bb8a-fda80a6cd6e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_path = \"/content/drive/MyDrive/bart_model\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def generate_summary_bart(dialogue):\n","    inputs = tokenizer(dialogue, return_tensors=\"pt\", padding=\"longest\", truncation=True).to(model.device)\n","    summary_ids = model.generate(\n","        inputs[\"input_ids\"],\n","        max_length=128,\n","        min_length=32,\n","        num_beams=4,\n","        length_penalty=2.0,\n","        early_stopping=True\n","    )\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n"],"metadata":{"id":"vzwJPn8BbceV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example dialogue\n","test_dialogues = [\n","   \"\"\"\n","ANU: \"Hey, can you give me an update on the project? How is the new feature development going?\"\n","\n","RAM: \"Sure! We've completed the initial development of the new feature. The team is now testing it for any bugs and making improvements based on the feedback. We expect to have it ready for a demo by next week.\"\n","\n","ANU: \"That sounds great! Have you encountered any major issues during testing?\"\n","\n","RAM: \"There were a few minor bugs, but nothing major. The team has been addressing them quickly. Overall, everything is on track.\"\n","\n","ANU: \"Perfect. Let me know if there's anything I can help with.\"\n","\"\"\"]\n","\n","summary = generate_summary_bart(test_dialogues)\n","print(\"Generated Summary:\")\n","print(summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eG8lP6qicKFf","executionInfo":{"status":"ok","timestamp":1724185301604,"user_tz":-60,"elapsed":1133,"user":{"displayName":"Niranjana B","userId":"06291036233969807225"}},"outputId":"7c85b96a-9d8c-44ad-d131-d2bad706eefd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Summary:\n","The team has completed the initial development of the new feature and is now testing it for any bugs and making improvements based on the feedback. They expect to have it ready for a demo by next week. There were a few minor bugs during the testing, but nothing major.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wJGbBPLeb3jL"},"execution_count":null,"outputs":[]}]}