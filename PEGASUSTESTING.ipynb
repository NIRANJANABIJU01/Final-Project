{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyP6u9Dcyp+tpk7HMtK3714v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oe-sN_ZISgX8","executionInfo":{"status":"ok","timestamp":1724149280774,"user_tz":-60,"elapsed":20900,"user":{"displayName":"Niranjana B","userId":"06291036233969807225"}},"outputId":"a80aebb5-2195-46a0-ed63-9765f8e92b9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model_save_path = \"/content/drive/MyDrive/your_model_directory\"\n","\n","model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_save_path).to(device)\n","tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n"],"metadata":{"id":"hbb8emxoTa7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test the model\n","def generate_summary(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"longest\").to(device)\n","    summary_ids = model_pegasus.generate(inputs[\"input_ids\"], max_length=128, min_length=32, num_beams=8, length_penalty=0.8)\n","    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"],"metadata":{"id":"jdYFZZxNTK5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test example\n","test_text = \"\"\"\n","ANU: \"Hey, can you give me an update on the project? How is the new feature development going?\"\n","\n","RAM: \"Sure! We've completed the initial development of the new feature. The team is now testing it for any bugs and making improvements based on the feedback. We expect to have it ready for a demo by next week.\"\n","\n","ANU: \"That sounds great! Have you encountered any major issues during testing?\"\n","\n","RAM: \"There were a few minor bugs, but nothing major. The team has been addressing them quickly. Overall, everything is on track.\"\n","\n","ANU: \"Perfect. Let me know if there's anything I can help with.\"\n","\"\"\"\n","\n","summary = generate_summary(test_text)\n","print(\"Generated Summary:\")\n","print(summary)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQnENsjHT-0n","executionInfo":{"status":"ok","timestamp":1724149747938,"user_tz":-60,"elapsed":1108,"user":{"displayName":"Niranjana B","userId":"06291036233969807225"}},"outputId":"502adc2a-1264-460b-f3b3-cdeca93de9ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Summary:\n","RAM has completed the initial development of the new feature. The team is now testing it for any bugs and making improvements based on the feedback. The new feature will be ready for a demo by next week.\n"]}]}]}